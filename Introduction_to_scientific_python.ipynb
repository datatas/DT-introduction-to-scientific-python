{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_scientific_python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMP9P5po+TupRbD8djllZBc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicpittman/DT-introduction-to-scientific-python/blob/main/Introduction_to_scientific_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNQKt5xAZH1"
      },
      "source": [
        "## Introduction to Scientific Programming in Python\n",
        "#### Presented by Nic Pittman, 08/04/2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK7h2Y6nAsVU"
      },
      "source": [
        "### Key lessons for today\n",
        "- Scientific Python packages and dependencies\n",
        "- Getting started on google colab rather than using Anaconda or Miniconda locally\n",
        "- Basic data structures\n",
        "- Introduction to Numpy\n",
        "- Introduction to Matplotlib\n",
        "- Introduction to Pandas\n",
        "- Introduction to Xarray\n",
        "- Intermediate and advanced data processing\n",
        "\n",
        "\n",
        "You can more complete resources here. There is a huge amount of information online and python and libraries have good help documentation.\n",
        "\n",
        "Basic Data Structures:\n",
        "https://github.com/jrjohansson/scientific-python-lectures/blob/master/Lecture-1-Introduction-to-Python-Programming.ipynb\n",
        "\n",
        "Numpy:\n",
        "https://github.com/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb\n",
        "\n",
        "Pandas: https://github.com/dlab-berkeley/introduction-to-pandas/blob/master/introduction-to-pandas.ipynb\n",
        "https://github.com/guiwitz/NumpyPandas_course \n",
        "\n",
        "\n",
        "Other: https://github.com/jrjohansson/scientific-python-lectures (Including SciPy and Matplotlib+ Advanced topics)\n",
        "\n",
        "CLEX Python and programming videos (Highly recommend) https://www.youtube.com/user/COECSSCMS/videos\n",
        "\n",
        "Lots of beginner to advanced posts on a variety of scientific python \n",
        "topics here: https://climate-cms.org/\n",
        "\n",
        "\n",
        "Sample Matplotlib library https://matplotlib.org/stable/tutorials/introductory/sample_plots.html \n",
        "\n",
        "SciPy Intro to python lectures https://scipy-lectures.org/intro/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mShdQmFkHr"
      },
      "source": [
        "## Part 1: Getting started on Conda\n",
        "\n",
        "I am not going to go into lots of detail about Anaconda.\n",
        "Basically, its similar to what you are running here (Google colab has something similar set up).\n",
        "You can have different environments and install different packages.\n",
        "\n",
        "Look at https://docs.anaconda.com/anaconda/install/\n",
        "Miniconda is a liteweight alternative\n",
        "\n",
        "Pangeo is a standard set of open source library of packages for reproducible research https://pangeo.io/. Semi-advanced use, but generally refers to the suite of packages used in this tutorial.\n",
        "\n",
        "Many people recommend using Jupyter (This is a Jupyter notebook). I use it sometimes, but prefer to use Spyder, an IDE (Interactive Development Environment) very similar to Matlab and R. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTMk2M4JAUs6"
      },
      "source": [
        "## Part 2: Scientific Python Packages and Dependencies\n",
        "\n",
        "Python is open source software, that has the core libaries, and then many additional libraries available to use.\n",
        "\n",
        "We will be using Python version 3.7. Please don't try learn 2.x as it is depreciated.\n",
        "\n",
        "The libraries we will focus on today for scientific analysis are as below. \n",
        "\n",
        "We can use them using their conventional short names. Later, we will be able to call functions within numpy, for example, np.array()\n",
        "\n",
        "Convention says we put these imports at the top of our document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZtnY4IPtOqf"
      },
      "source": [
        "#Lets get these installations out of the way so we can use certain extra packages not included in \n",
        "!pip install erddapy\n",
        "!pip install xarray\n",
        "!pip install netcdf4\n",
        "!pip install cmocean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h7AxyPlm_5I"
      },
      "source": [
        "#https://numpy.org/\n",
        "import numpy as np                  #Numpy is a useful scientific package for large datasets. It is different to the core python array system.\n",
        "\n",
        "#https://pandas.pydata.org/\n",
        "import pandas as pd                 #Pandas is built on top of numpy, but uses labels, much like a table in excel. This can make it easier to access certain attributes,\n",
        "                                    #rather than remembering which dimension they are on.\n",
        "\n",
        "#http://xarray.pydata.org/en/stable/                                \n",
        "import xarray as xr                 #Xarray is a combination of numpy and pandas, but for n-dimensional data. It uses computational efficiencies and can load very large datasets.\n",
        "\n",
        "#https://matplotlib.org/\n",
        "import matplotlib.pyplot as plt     #Matplotlib is how we will be plotting all of our data. \n",
        "import matplotlib\n",
        "\n",
        "#https://seaborn.pydata.org/\n",
        "import seaborn as sns               #A wrapper for matplotlib and statistics packages to make nice R-like plots\n",
        "\n",
        "#https://www.scipy.org/\n",
        "import scipy                        #Has loads of advanced and useful statistical, machine learning and other packages (If you want machine learning though, I recommend Keras or PyTorch)\n",
        "import cmocean                      #Some nice colourmaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WehFiR-IW6"
      },
      "source": [
        "## Part 3: Basic python data structures\n",
        "Great! Even though we are on collab and don't need the other two points, you will need them when working locally.\n",
        "\n",
        "There is a lot of content in the Python Standard Libary\n",
        "https://docs.python.org/3/library/\n",
        "\n",
        "Lets get started!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXBqHj4jLQma"
      },
      "source": [
        "#First of all, you can check the help of any thing in namespace (what python can see) in iPython (interactive python used by Jupyter) by using\n",
        "?str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQH-W5LLEk5D"
      },
      "source": [
        "#You do not need to define types explicitely in python as it will do it automagically, but it can sometimes help:\n",
        "print(3+1)\n",
        "print('Three'+'One')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2U3jiHiE7pw"
      },
      "source": [
        "#For example:\n",
        "print('Three'+1) #Oops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdeVj8PE_ty"
      },
      "source": [
        "#So we need to either define them like:\n",
        "print(int('3')+1)\n",
        "#or\n",
        "print('three'+str(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umrF2660El3w"
      },
      "source": [
        "#### Lets look at arrays. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Gs2TDYDJyl"
      },
      "source": [
        "my_array=['Element 1','Element 2'] \n",
        "\n",
        "#We an add new elements to the array like:\n",
        "my_array.append('Element 3')\n",
        "my_array.append('Element 4')\n",
        "print(my_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGx4yyIdDvhQ"
      },
      "source": [
        "#But remember, Python indexing starts at 0, not 1 like in other languages\n",
        "print(my_array[1])\n",
        "#so we need to do this instead:\n",
        "print(my_array[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weVEIk0eDH4H"
      },
      "source": [
        "#You can also go backwards\n",
        "print(my_array[-1])\n",
        "\n",
        "#or select a small component\n",
        "print(my_array[1:3])\n",
        "\n",
        "#or even reverse the whole thing\n",
        "print(my_array[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4JYFCZII3k"
      },
      "source": [
        "#There are also python functions like this (I'm not going to talk about all of them)\n",
        "print(len(my_array)) #Can you work out what this is?\n",
        "#how about\n",
        "print(range(len(my_array)))\n",
        "#This could be useful later. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMwgqKaEHYj"
      },
      "source": [
        "####We can make two dimensional arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlK4OhULB8cr"
      },
      "source": [
        "my2d_array=[[1,2,3,4,5,6,7,8,9,10],[100,200,300,400,500,600,700],[1000,2000,3000,4000,5000]]\n",
        "print(my2d_array)\n",
        "#But if I only want the thousand I need to remember:\n",
        "print(my2d_array[2]) \n",
        "#or even\n",
        "print(my2d_array[2][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbuwgMI4ESz5"
      },
      "source": [
        "#### Ok how about something that remembers something else: a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0oiK9FQ-Vrw"
      },
      "source": [
        "this_is_a_dictionary={'Key':'Data'}\n",
        "print(this_is_a_dictionary)\n",
        "print(this_is_a_dictionary['Key'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wcw-RYJ-Y-I"
      },
      "source": [
        "#You can add extra keys and values like:\n",
        "this_is_a_dictionary['mynewkey'] = 'more data'\n",
        "this_is_a_dictionary['anotherkey'] = 'even more data'\n",
        "print(this_is_a_dictionary)\n",
        "#Very useful for lookups. But there are better tools for the job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACdwP6dtoKKx"
      },
      "source": [
        "### Quick overview of Python control flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqV5jFO5oJf4"
      },
      "source": [
        "#Quick summary of control flow\n",
        "\n",
        "if 1==5:\n",
        "  print('1 equals five')\n",
        "else:\n",
        "  print(\"We know that 1 does not equal 5\")\n",
        "\n",
        "print('\\nFor loop')\n",
        "for i in range(5):\n",
        "  print(i)\n",
        "\n",
        "print('\\nWhile loop')\n",
        "x=5\n",
        "while x!=0:\n",
        "  print(x)\n",
        "  x-=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7TQ5bf0G_XP"
      },
      "source": [
        "## Part 4: Numpy\n",
        "\n",
        "Lets use what we just learnt in a more practical way. \n",
        "\n",
        "Numpy does lots and lots of stuff and this is a very brief overview. \n",
        "\n",
        "Check here for more information: \n",
        "https://numpy.org/devdocs/user/absolute_beginners.html\n",
        "\n",
        "How numpy actually stores data: https://numpy.org/doc/stable/reference/internals.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0QJ-ouNEcA3"
      },
      "source": [
        "#Great. We understand basic python syntax and datatypes\n",
        "#How about this\n",
        "my_numpy_array=np.array([1,2,3,4,5])\n",
        "print(my_numpy_array)\n",
        "print(my_numpy_array[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4yb9VtpHMMy"
      },
      "source": [
        "#Ok so what is different?\n",
        "#First of all you can't do this\n",
        "my_numpy_array.append([6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwZa6WHVHX3Q"
      },
      "source": [
        "#Which I agree is a bit funny. But its all about the way the data is stored, and that Numpy uses objects. You'll need to do this instead which is a bit clunky\n",
        "my_numpy_array=np.append(my_numpy_array,6) #Dont forget = because this function only returns, not rewrite the array.\n",
        "print(my_numpy_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUHbhB53HgO7"
      },
      "source": [
        "#but we have modifiers like\n",
        "print(my_numpy_array.shape)\n",
        "#or even:\n",
        "my_new_numpy_array=my_numpy_array.reshape(3, 2)\n",
        "print(my_new_numpy_array)\n",
        "print(my_new_numpy_array.shape)\n",
        "#They have better info so lets go here: https://numpy.org/devdocs/user/absolute_beginners.html\n",
        "\n",
        "#Numpy also has inbuilt functions like (and many others, check their docs!):\n",
        "print(np.arange(0,10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oywGvNI2H-Jg"
      },
      "source": [
        "# A cool example of why numpy really is better https://www.geeksforgeeks.org/why-numpy-is-faster-in-python/ (also https://towardsdatascience.com/how-fast-numpy-really-is-e9111df44347)\n",
        "# importing required packages\n",
        "import numpy\n",
        "import time\n",
        " \n",
        "# size of arrays and lists\n",
        "size = 1000000  \n",
        " \n",
        "# declaring lists\n",
        "list1 = range(size)\n",
        "list2 = range(size)\n",
        " \n",
        "# declaring arrays\n",
        "array1 = numpy.arange(size) \n",
        "array2 = numpy.arange(size)\n",
        " \n",
        "# list\n",
        "initialTime = time.time()\n",
        "resultantList = [(a * b) for a, b in zip(list1, list2)]\n",
        " \n",
        "# calculating execution time\n",
        "print(\"Time taken by Lists :\",\n",
        "      (time.time() - initialTime),\n",
        "      \"seconds\")\n",
        " \n",
        "# NumPy array\n",
        "initialTime = time.time()\n",
        "resultantArray = array1 * array2\n",
        " \n",
        "# calculating execution time\n",
        "print(\"Time taken by NumPy Arrays :\",\n",
        "      (time.time() - initialTime),\n",
        "      \"seconds\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75GoIwiLLnRj"
      },
      "source": [
        "## Part 5: Pandas\n",
        "Now that we know numpy is the bees knees, how can we build on this knowledge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svtCGTkvvCZn"
      },
      "source": [
        "#### Pandas Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0G6R5ntcz8"
      },
      "source": [
        "print(this_is_a_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5x_SdNHI-7S"
      },
      "source": [
        "my_pandas_series=pd.Series(this_is_a_dictionary)\n",
        "print(my_pandas_series)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAN8GJxiOtSl"
      },
      "source": [
        "#### Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZlfJvB8LMJ6"
      },
      "source": [
        "#And we can turn this into a nice 2d table\n",
        "\n",
        "my_dataframe=pd.Series(my_pandas_series).to_frame('ColumnName')\n",
        "my_dataframe.head(5)\n",
        "\n",
        "#print(my_dataframe.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsEt14XUww1J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YotJqRaPvK0E"
      },
      "source": [
        "#But now we could add more columns very easily\n",
        "my_dataframe['Score']=[9,5,1]\n",
        "print(my_dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l50r8nlWw7aM"
      },
      "source": [
        "#Pandas will let us use dot notation for our column names.\n",
        "my_dataframe.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz1Ks5BQxBcY"
      },
      "source": [
        "This is a bad example so lets check what other people have done: https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/ or even https://github.com/dlab-berkeley/introduction-to-pandas/blob/master/introduction-to-pandas.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-IbIvZFOnoW"
      },
      "source": [
        "## Part 6: Introduction to xarray\n",
        "\n",
        "This one is probably the library I use the most, is probably the most powerful library but has the worst documentation/learning curve of everything.\n",
        "Basically creates a n-Dimensional pandas dataframe, but uses computational efficiencies (Dask) to be efficient and load massive datasets into memory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOtc06_9Ssvc"
      },
      "source": [
        "#This comes straight off the xarray webpage for OpenDAP\n",
        "#http://xarray.pydata.org/en/stable/io.html\n",
        "\n",
        "#remote_data = xr.open_dataset(\n",
        "#    \"http://iridl.ldeo.columbia.edu/SOURCES/.OSU/.PRISM/.monthly/dods\",\n",
        "#\n",
        "#    decode_times=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSWACDl-v1Sp"
      },
      "source": [
        "\n",
        "#but lets use my dataset because we can\n",
        "#Nics Dataset: https://geonetwork.nci.org.au/geonetwork/srv/eng/catalog.search#/metadata/f3440_0961_0590_6154\n",
        "\n",
        "\n",
        "#2002 only starts in July. This is a small dataset, but may cause problems because many simultaneous data tranfers via google colab. Example of how this can be expanded below\n",
        "nics_chlorophyll = xr.open_dataset(\n",
        "    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2002.nc\",\n",
        "    decode_times=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76ilG1PfzshS"
      },
      "source": [
        "nics_chlorophyll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLMkZPiw0fHw"
      },
      "source": [
        "nics_chlorophyll.nbytes/1e9 #Size in GB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sureg4vdz2d2"
      },
      "source": [
        "nics_chlorophyll.load() #This loads the dataset into memory (RAM) so we can use it faster. Not always recommended for large datasets. Will take a while. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iak0M5qAz7Hm"
      },
      "source": [
        "#xarray wrapper for Matplotlib is very useful!\n",
        "nics_chlorophyll.chl_tpca.mean(dim='time').plot(vmin=0,vmax=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEb-4KNF1nkw"
      },
      "source": [
        "#Or we could make a hovmoller\n",
        "nics_chlorophyll.chl_tpca.mean(dim='lon').T.plot(vmin=0,vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5RRLMwM11I1"
      },
      "source": [
        "#Or even just a timeseries for 2N-2S\n",
        "nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2)).mean(dim=['lat','lon']).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuKqcR452Ih-"
      },
      "source": [
        "#Or just the Gal√°pagos region\n",
        "nics_chlorophyll.chl_tpca.sel(lat=slice(5,-5),lon=slice(265,280)).mean(dim=['lat','lon']).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJuurRizmNE"
      },
      "source": [
        "#An example how to load the entire timeseries. There are more elegant ways of doing this. Especially if the files are stored locally, you can use wildcard so would look more like:\n",
        "#/path/to/my/dataset/tpca_modis_aqua_*.nc   ... But we can't call the wildcard when stored remotely like in this example\n",
        "\n",
        "#Suggest not running the below example as it will probably time all of us out. \n",
        "\n",
        "#nics_chlorophyll_all= xr.open_mfdataset(\n",
        "#    [\"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2002.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2003.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2004.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2005.nc\",   \n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2006.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2007.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2008.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2009.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2010.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2011.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2012.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2013.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2014.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2015.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2016.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2017.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2018.nc\",\n",
        "#    \"http://dapds00.nci.org.au/thredds/dodsC/ks32/CLEX_Data/TPCA_reprocessing/v2019_01/MODIS-Aqua/tpca_modis_aqua_2019.nc\"],\n",
        "#    decode_times=True,combine='nested'\n",
        "#)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srnYHTmJHUmp"
      },
      "source": [
        "## Part 7: Matplotlib and Advanced plotting\n",
        "Lots of good resources. I will provide a quick summary, but encourage you to watch these two videos from CLEX\n",
        "\n",
        "\n",
        "Intro: https://www.youtube.com/watch?v=5MoSx4GftK\n",
        "Advanced: https://www.youtube.com/watch?v=O3F2xrFHgKw \n",
        "\n",
        "Cartopy (https://scitools.org.uk/cartopy/docs/latest/) is very useful to make georeferenced maps. But is not covered during this tutorial "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL9ux2Ry79Wx"
      },
      "source": [
        "chl_subset=nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2))\n",
        "plt.plot(chl_subset.time,chl_subset.mean(dim=['lat','lon']))\n",
        "plt.title('Home Made')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y16IT6lXwEyi"
      },
      "source": [
        "#Lets make the same plots that xarray made in a subplot to show the difference\n",
        "#Multiple ways to do this\n",
        "ax1=plt.subplot(211)\n",
        "\n",
        "chl_subset=nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2))\n",
        "ax1.plot(chl_subset.time,chl_subset.mean(dim=['lat','lon']))\n",
        "plt.title('Home Made')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Chlorophyll concentration (Mg m$^{-3}$)')\n",
        "\n",
        "ax2=plt.subplot(212)\n",
        "nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2)).mean(dim=['lat','lon']).plot(ax=ax2)\n",
        "plt.title('Xarray wrapper')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXDtSfmx390C"
      },
      "source": [
        "def plot_linear_trend(ax,x,y):\n",
        "  \"\"\"\n",
        "  Quick linear trend function wrapping scipy.\n",
        "  \"\"\"  \n",
        "  #Little cheat to get times to work properly\n",
        "  #assert type(chl_subset.time.values[0])==np.datetime64()\n",
        "  \n",
        "  x_fake = pd.to_numeric(chl_subset.time.values.astype('datetime64[D]'))\n",
        "\n",
        "  x_fake=np.ravel(x_fake)\n",
        "  y=np.ravel(y)\n",
        "  mask=~np.isnan(x_fake)\n",
        "  x_fake=x_fake[mask]\n",
        "  y=y[mask]\n",
        "  \n",
        "  slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x_fake,y)\n",
        "\n",
        "  #Depending on the type, x might need some management \n",
        "  mn=min(x_fake)\n",
        "  mx=max(x_fake)\n",
        "  x1=np.linspace(mn,mx,len(x))\n",
        "  y1=slope*x1+intercept\n",
        "  ax.plot(x.values,y1,'r',linewidth=2)\n",
        "\n",
        "    \n",
        "  return slope, intercept, r_value, p_value, std_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFP4ef7J8126"
      },
      "source": [
        "#matplotlib.rc_file_defaults()\n",
        "#What if we want a bigger plot ... This is probably recommended\n",
        "#Lets make the same plots that xarray made in a subplot to show the difference\n",
        "\n",
        "#Can you notice any differences with the above example? Hint, add_subplot and subplot are different methods. Welcome to Object Oriented programming in Python!\n",
        "fig=plt.figure(figsize=(8,10))\n",
        "\n",
        "ax1=fig.add_subplot(211)\n",
        "\n",
        "chl_subset=nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2))\n",
        "ax1.plot(chl_subset.time,chl_subset.mean(dim=['lat','lon']))\n",
        "ax1.set_title('Home Made')\n",
        "ax1.set_xlabel('Time',)\n",
        "ax1.set_ylabel('Chlorophyll concentration (Mg m$^{-3}$)')\n",
        "chl_2002=plot_linear_trend(ax1,chl_subset.time,chl_subset.mean(dim=['lat','lon']).values)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "#Lets also put a trend line through it because thats useful!\n",
        "\n",
        "#plt refers to the current axis\n",
        "\n",
        "ax2=fig.add_subplot(212)\n",
        "nics_chlorophyll.chl_tpca.sel(lat=slice(2,-2)).mean(dim=['lat','lon']).plot(ax=ax2)\n",
        "ax2.set_title('Xarray wrapper')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(chl_2002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOxKuHKd9lKZ"
      },
      "source": [
        "# Ok lets make the hovmoller in two different ways\n",
        "plt.pcolormesh(nics_chlorophyll.time,nics_chlorophyll.lat,nics_chlorophyll.chl_tpca.mean(dim='lon').T,vmin=0,vmax=1)\n",
        "plt.colorbar(extend='both')\n",
        "plt.show()\n",
        "\n",
        "#something wrong with time index\n",
        "plt.contour(nics_chlorophyll.time.astype(int),nics_chlorophyll.lat,nics_chlorophyll.chl_tpca.mean(dim='lon').T,levels=np.arange(0,1,0.01))\n",
        "plt.colorbar(extend='both')\n",
        "plt.show()\n",
        "#nics_chlorophyll.chl_tpca.mean(dim='lon').T.plot(vmin=0,vmax=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkzgQs5CPMfS"
      },
      "source": [
        "## Part 8: Seaborn statistical plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gj3q73Wvk6S"
      },
      "source": [
        "#https://seaborn.pydata.org/introduction.html\n",
        "#https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html\n",
        "sns.set_theme()\n",
        "##matplotlib.rc_file_defaults()\n",
        "sns.get_dataset_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcUI1ofSv7YW"
      },
      "source": [
        "\n",
        "# Load an example dataset\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "print(penguins.shape)\n",
        "penguins.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3miy7t5Ryde5"
      },
      "source": [
        "sns.pairplot(penguins, hue=\"species\",diag_kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTKji5qdrZ-3"
      },
      "source": [
        "#Create a visualization\n",
        "sns.relplot(\n",
        "    data=penguins,\n",
        "    x=\"body_mass_g\", y=\"bill_length_mm\", col=\"sex\",\n",
        "    hue=\"species\",style='island')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPviz_19yDVW"
      },
      "source": [
        "#Create a visualization\n",
        "sns.lmplot(\n",
        "    data=penguins,\n",
        "    x=\"body_mass_g\", y=\"bill_length_mm\", hue=\"species\")\n",
        "#But we will need to calculate the coefficients ourselves using scipy.stats.linregress\n",
        "#This code will drop na values because linregress doesn't like them.\n",
        "#Will only calculate all penguins, not split by species. Bonus question is how to calculate the different ones, and also how to put text on the plot\n",
        "penguin_data=penguins.dropna()\n",
        "scipy.stats.linregress(penguin_data.body_mass_g,penguin_data.bill_length_mm) #All penguins without NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLv2V5hZIBc6"
      },
      "source": [
        "#Rearange the chlorophyll data into a pandas DataFrame\n",
        "chl_pandas=nics_chlorophyll.mean(dim=['lat','lon']).to_dataframe() \n",
        "chl_pandas.reset_index(level=0, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zorx8HzcTXm5"
      },
      "source": [
        "chl_pandas.chl_tpca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdeRO81JGgJa"
      },
      "source": [
        "sns.regplot(data=chl_pandas,x='time',y='chl_tpca')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1QDhrKBHtin"
      },
      "source": [
        "#Try something yourself?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN9AeMQ4HFCz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1OKYjpzrRm0"
      },
      "source": [
        "## Part 9: Functions specifically for plotting subplots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cSSEhioa55N"
      },
      "source": [
        "nics_chlorophyll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbPhK8k1rR3z"
      },
      "source": [
        "def regional_chl_plot(f,axs,axn,xarr,lat,lon,region_size=5):\n",
        "    \"A quick wrapper to make subplots on the fly\"\n",
        "    ax=f.add_subplot(axs/2,2,axn+1) #+1 because matplotlib starts at 1... \n",
        "    data=xarr.sel(lat=slice(lat+region_size,lat-region_size),lon=slice(lon-region_size,lon+region_size))\n",
        "    data=data.mean(dim=['lat','lon']).chl_tpca\n",
        "    ax.plot(data.time,data.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFEQvCNba8Dk"
      },
      "source": [
        "f=plt.figure(figsize=(10,10))\n",
        "regional_chl_plot(f,6,0,nics_chlorophyll,2,170)\n",
        "regional_chl_plot(f,6,1,nics_chlorophyll,-5,165)\n",
        "regional_chl_plot(f,6,2,nics_chlorophyll,5,200)\n",
        "regional_chl_plot(f,6,3,nics_chlorophyll,-5,200)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OraZLbwkXO7x"
      },
      "source": [
        "## Part 10: Defensive programming\n",
        "Overview of testing your code and handling errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdFTvNPFHUKw"
      },
      "source": [
        "try:\n",
        "  thisisgointofail \n",
        "except:a\n",
        "  print('This will occur because the other one did fail')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji0A9C1sXtS3"
      },
      "source": [
        "assert 1==1\n",
        "assert 1==2 #But one does not equal two"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjiycsUKXuyA"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae6U29Wd9OP_"
      },
      "source": [
        "## Part 11: Interesting extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JB-JycMTrZM"
      },
      "source": [
        "#Interesting variables to play with from earlier can include:\n",
        "\n",
        "nics_chlorophyll #1 year of daily chlorophyll data from MODIS Aqua \n",
        "chl_pandas #Chlorophyll dataset mean in pandas form\n",
        "penguins #An interesting Seaborn library (and check inside there are many more example datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEHZ6smom_tV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-mMtAgPm_nl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVXnXWKm_dY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "207J9gVpEH8H"
      },
      "source": [
        "#Check this cool plot out from https://scipython.com/blog/recamans-sequence/\n",
        "\n",
        "# Equal aspect ratio Figure with black background and no axes.\n",
        "fig, ax = plt.subplots(facecolor='k')\n",
        "ax.axis('equal')\n",
        "ax.axis('off')\n",
        "\n",
        "# Colour the lines sequentially from a Matplotlib colormap.\n",
        "cm = plt.cm.get_cmap('Spectral')\n",
        "\n",
        "def add_to_plot(lasta, a, n):\n",
        "    \"\"\"Add a semi-circular arc from a to lasta.\n",
        "\n",
        "    Arcs alternate to be above and below the x-axis according to whether\n",
        "    n is even or odd.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Arc centre and radius.\n",
        "    c, r = (a + lasta) / 2, abs(a - lasta) / 2\n",
        "    x = np.linspace(-r, r, 1000)\n",
        "    y = np.sqrt(r**2 - x**2) * (-1)**n\n",
        "    color = cm(n/max_terms)\n",
        "    ax.plot(x+c, y, c=color, lw=1)\n",
        "\n",
        "# Keep track of which numbers have been \"visited\" in this set.\n",
        "seen = set()\n",
        "n = a = 0\n",
        "lasta = None\n",
        "max_terms = 60\n",
        "while n < max_terms:\n",
        "    lasta = a\n",
        "    b = a - n\n",
        "    if b > 0 and b not in seen:\n",
        "        a = b\n",
        "\n",
        "    else:\n",
        "        a = a + n\n",
        "    seen.add(a)\n",
        "    n += 1\n",
        "    print(a)\n",
        "    add_to_plot(lasta, a, n)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT6rRK0G9VfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}